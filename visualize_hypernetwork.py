import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim.lr_scheduler import ExponentialLR
import torch.nn.init as init

import torchvision
from torchvision.datasets import MNIST
from torchvision import datasets, transforms
from torch.utils.data import Subset

import matplotlib.pyplot as plt
from collections import Counter
from functools import reduce
import urllib.request
import numpy as np
import random
import time
import os

class OneShotMetaDataset:
    def __init__(self, dataset, device=None):
        self.device = device
        self.images = torch.stack([img for img, _ in dataset])
        self.labels = torch.tensor([label for _, label in dataset])

        self.classes = torch.unique(self.labels).tolist()
        self.indices_per_class = {c: torch.where(self.labels == c)[0] for c in self.classes}

    def create_query(self, query_size: int):
        c_tr = random.choice(self.classes)
        class_indices = self.indices_per_class[c_tr]

        perm = torch.randperm(len(class_indices))
        xtr_idx = class_indices[perm[0]].item()
        pos_indices = class_indices[perm[1:1 + query_size // 2]]

        xtr = (self.images[xtr_idx], self.labels[xtr_idx].item())

        neg_class_indices = torch.cat([self.indices_per_class[c] for c in self.classes if c != c_tr])
        perm = torch.randperm(len(neg_class_indices))
        neg_indices = neg_class_indices[perm[:query_size // 2]]

        all_indices = torch.cat([pos_indices, neg_indices])
        perm_all = torch.randperm(len(all_indices))
        shuffled_idx = all_indices[perm_all]

        query = [(self.images[i], lbl.item(), int(lbl.item() == c_tr)) for i, lbl in zip(shuffled_idx, self.labels[shuffled_idx])]

        if self.device is not None:
            xtr = (xtr[0].to(self.device), xtr[1])
            query = [(img.to(self.device), lbl, binary_lbl) for img, lbl, binary_lbl in query]
        return xtr, query


# Define the architecture of the neural network
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()

        # Feature extraction CNN
        self.feature_net = nn.Sequential(
          nn.Conv2d(1, 32, kernel_size=3, padding=1),   # → 32×28×28
          nn.BatchNorm2d(32),
          nn.ReLU(),
          nn.MaxPool2d(2),                              # → 32×14×14

          nn.Conv2d(32, 64, kernel_size=3, padding=1),  # → 64×14×14
          nn.BatchNorm2d(64),
          nn.ReLU(),
          nn.MaxPool2d(2),                              # → 64×7×7

          nn.Conv2d(64, 128, kernel_size=3, padding=1), # → 128×7×7
          nn.BatchNorm2d(128),
          nn.ReLU(),
          nn.MaxPool2d(2),                              # → 128×3×3

          nn.AdaptiveAvgPool2d(1),                      # → 128×1×1
          nn.Flatten(),                                 # → [B, 128]
          nn.Dropout(0.3)
        )
        feat_dim = 128

        # main-net layer dimensions
        self.layers_dim = [feat_dim, 64, 1]

        # Total main network parameters (weights + biases)
        # Matches hypernetwork output dimension
        self.main_param_cnt  = sum(
            [self.layers_dim[i] * self.layers_dim[i + 1] + self.layers_dim[i + 1]
             for i in range(len(self.layers_dim) - 1)])

        # Initialize embedding vector
        self.embedding = torch.zeros(1, feat_dim)

        # Full hypernetwork, takes embedding input and outputs weights of the main network
        self.hypernet = nn.Sequential(
          nn.Linear(feat_dim, 256), nn.ReLU(), nn.Dropout(0.2),
          nn.Linear(256, 256), nn.ReLU(), nn.Dropout(0.2),
          nn.Linear(256, self.main_param_cnt)
        )
        """
        # Glorot Initialization for HyperNetwork parameters
        for hlayer in self.hypernet:
            if isinstance(hlayer, nn.Linear):
              gain = init.calculate_gain('relu')
              init.xavier_normal_(hlayer.weight, gain=gain)
              if hlayer.bias is not None:
                  nn.init.zeros_(hlayer.bias)
        """

        # Main network structure (dummy initialization)
        # The actual weights will be dynamically generated by the hypernetwork
        self.main_net = nn.Sequential(
            nn.Linear(self.layers_dim[0], self.layers_dim[1]),
            nn.ReLU(),
            nn.Linear(self.layers_dim[1], self.layers_dim[2]),
        )

        # main_net weights should not be updated via backpropagation
        for p in self.main_net.parameters():
            p.requires_grad = False

    # Generates and assigns weights to the main network from the hypernetwork
    def sample_weights(self):
        # Get the main network parameters from the hypernetwork output
        self.hypernet_outputs = self.hypernet(self.embedding)[0]

        # Split and assign generated weights and biases to main_net layers
        next_idx = 0
        for i in range(len(self.layers_dim) - 1):
            in_dim = self.layers_dim[i]
            out_dim = self.layers_dim[i + 1]

            # Extract weight slice and reshape
            cur_idx = next_idx
            next_idx += in_dim * out_dim
            weights_slice = self.hypernet_outputs[cur_idx:next_idx].reshape([out_dim, in_dim])

            # Assign generated weights
            del self.main_net[i * 2].weight
            self.main_net[i * 2].weight = weights_slice

            # Extract bias slice and assign
            cur_idx = next_idx
            next_idx += out_dim
            bias_slice = self.hypernet_outputs[cur_idx:next_idx].reshape(out_dim)
            del self.main_net[i * 2].bias
            self.main_net[i * 2].bias = bias_slice

    def forward(self, x):
        # Extract features from input
        z = self.feature_net(x)

        # Flatten for fully-connected layers
        z = z.view(z.size(0), -1)

        # Predict using dynamically generated main_net
        return self.main_net(z)


def train(model, device, obj_train_data, optimizer, iteration_count, query_size):
    model.train()

    train_object = obj_train_data
    repeats=1 # M value

    for i in range(iteration_count):

      all_logits = []
      all_labels = []

      for episode in range(repeats):

        # Draw a support example x_tr and a balanced query set Q
        # Half of Q has the same class as x_tr (positives),
        # the other half a different class (negatives)
        (xtr_img, xtr_label), query = train_object.create_query(query_size)

        xtr_img = xtr_img.to(device)

        query_imgs = torch.stack([img for img,_,_ in query]).to(device)
        query_y_label = torch.tensor([b for _,_,b in query], dtype=torch.float32, device=device)

        # x_tr -> CNN -> HyperNet -> Update main net param
        feat = model.feature_net(xtr_img.unsqueeze(0).to(device))
        model.embedding = feat.view(1, -1)
        model.sample_weights() # Update main_net weights using hypernet

        # Forward pass query images
        logits = model(query_imgs).squeeze()
        all_logits.append(logits)
        all_labels.append(query_y_label)

      all_logits = torch.cat(all_logits, dim=0)
      all_labels = torch.cat(all_labels, dim=0)

      # Contruct losss
      loss = F.binary_cross_entropy_with_logits(all_logits, all_labels)

      # Model update for only CNN and HyperNet
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()


def test(model, device, iteration_count, query_size,  obj_test_data=None, created_traindata=None):
    model.eval()

    total_correct = 0
    total_queries = 0

    # Determine which data sapmling source to use: dynamic generator or pre-created list
    if obj_test_data is not None:
        test_object = obj_test_data
    else:
      assert iteration_count <= len(created_traindata), f"iteration_count ({iteration_count}) cannot be greater than the number of available samples ({len(created_traindata)})."

    with torch.no_grad(): # Disable gradient tracking
        for i in range(iteration_count):

          # Sample one test episode: 1 support image + query set
          (xte_img,_), query = test_object.create_query(query_size) if (obj_test_data is not None) else created_traindata[i]

          xte_img = xte_img.to(device)

          query_imgs = torch.stack([img for img,_,_ in query])
          query_imgs = query_imgs.to(device)
          query_y_label = torch.tensor([b for _,_,b in query], dtype=torch.float32, device=device)

          # x_te -> CNN -> HyperNet -> Update main net param
          feat = model.feature_net(xte_img.unsqueeze(0).to(device))
          model.embedding = feat.view(1, -1)
          model.sample_weights() # Update main_net weights using hypernet

          # Forward pass query images through main_net
          logits = model(query_imgs).squeeze()

          # Binary predictions: threshold at 0
          preds  = (logits > 0).float()

          # Update correct prediction count
          total_correct += (preds == query_y_label).sum().item()
          total_queries += query_size

    # Compute final accuracy
    acc = 100. * total_correct / total_queries
    # print(f"\nOne-shot on digits 6–9 over {iteration_count} episodes:" f"  {total_correct}/{total_queries} correct → {acc:.2f}%\n")

    return acc


# Helper funtions for visualizing the pre-trained model performance.
def _plot_one_shot(support_img, query_imgs, preds, truths, acc):
    """
    support_img : 1×28×28  tensor
    query_imgs  : (N, 1, 28, 28)  (N=16)
    """
    rows = 3 
    cols=8

    fig, axes = plt.subplots(rows, cols, figsize=(cols*1.2, rows*1.2))

    # Turn the all axes off
    for ax in axes.flatten(): ax.axis("off")

    # Show support image
    axes[0, 0].imshow(support_img.squeeze(), cmap='gray')
    axes[0, 0].set_title("Support", fontsize=8)

    # Show query images
    idx = 0
    for r in range(1, rows):
        for c in range(cols):
            if idx >= len(query_imgs): break
            ax = axes[r, c]
            ax.imshow(query_imgs[idx].squeeze(), cmap='gray')

            color = "green" if preds[idx] == truths[idx] else "red"
            ax.set_title(f"P:{int(preds[idx])}", color=color, fontsize=12)
            idx += 1

    # Title
    fig.suptitle(f"Episode accuracy: {acc:.2f}%", fontsize=12, y=0.98)

    plt.tight_layout()
    plt.show()


def plot_one_shot(model, device, created_traindata):
    model.eval()
    total_correct = 0

    with torch.no_grad():
        (x_support, _), query = created_traindata

        x_support = x_support.to(device)

        query_imgs = torch.stack([img for img, _, _ in query]).to(device)
        query_truth = torch.tensor([b for _, _, b in query], dtype=torch.float32, device=device)

        # Main_net update
        feat = model.feature_net(x_support.unsqueeze(0))
        model.embedding = feat.view(1, -1)
        model.sample_weights()

        logits = model(query_imgs).squeeze()
        preds = (logits > 0).float()

        total_correct += (preds == query_truth).sum().item()
        acc = 100.0 * total_correct / 16

        _plot_one_shot(x_support.cpu(),
                              query_imgs.cpu(),
                              preds.cpu().numpy(),
                              query_truth.cpu().numpy(),
                              acc=acc)
    return acc


class VisualizeHyperNet:
    MODEL_URL  = ("https://github.com/HalilCandan/oneshot-hypernet-mnist/raw/refs/heads/main/saved_models/model1_75acc.pt")
    MODEL_PATH = "model1_75acc.pt"

    def __init__(self, device: str = "cpu"):

        self.device = torch.device(device)

        if not os.path.exists(self.MODEL_PATH):
            print("Model file not found – downloading …")
            urllib.request.urlretrieve(self.MODEL_URL, self.MODEL_PATH)
            print("Download complete.")

        self.model = Net().to(self.device)
        state = torch.load(self.MODEL_PATH, map_location=self.device)
        self.model.load_state_dict(state, strict=False)
        self.model.eval()

        mean, std = 0.1307, 0.3081
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((mean,), (std,))
        ])

        data_dir = "./mnist_data"
        full_train = MNIST(root=data_dir, train=True,
                           download=True, transform=transform)

        test_indices = [i for i, (_, lbl) in enumerate(full_train) if lbl >= 6]
        self.test_subset   = Subset(full_train, test_indices)
        self.meta_test_set = OneShotMetaDataset(self.test_subset, self.device)

    def test_model_accuracy(self, iteration_count: int = 100, query_size: int = 16):

        acc = test(self.model, self.device,
                   iteration_count=iteration_count,
                   query_size=query_size,
                   obj_test_data=self.meta_test_set)
        
        print(f"Average accuracy over {iteration_count} episodes: {acc:.2f}%")
        return acc

    def plot_model_prediction(self):
        one_shot = self.meta_test_set.create_query(16)
        plot_one_shot(self.model, self.device, created_traindata=one_shot)